# -*- coding: utf-8 -*-
"""Untitled32.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z4Mv1CT3ZmRsbBo4npT22UyzoJDP3yJv
"""

!pip install transformers streamlit torchvision

from transformers import BlipProcessor, BlipForConditionalGeneration
import streamlit as st
from PIL import Image

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Streamlit app setup
st.title("AI-Based Image Caption Generator")
st.write("Upload an image to generate a caption.")

from google.colab import files
uploaded = files.upload()

processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")

# Load the uploaded image
image_path = next(iter(uploaded))  # Get the first uploaded file
image = Image.open(image_path).convert("RGB")

# Display the uploaded image
image.show()  # Show the uploaded image

# Prepare image for model
inputs = processor(image, return_tensors="pt")

# Generate caption
out = model.generate(**inputs)
caption = processor.decode(out[0], skip_special_tokens=True)

# Display the generated caption
print(f"Generated Caption: {caption}")